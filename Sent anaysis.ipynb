{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "### **Author:** ***Martin Waweru***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## The project will CRISP-DM Criteria\n",
    "Business understanding  \n",
    "Data Understanding  \n",
    "Data preparation  \n",
    "Modeling  \n",
    "Evaluation  \n",
    "Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "### Business Problem\n",
    "Businesses face the challenge of analyzing large volumes of unstructured text data, such as customer reviews and social media posts, to understand sentiment. Manual analysis is time-consuming and inefficient, creating a need for an automated solution to classify text into positive, negative, or neutral sentiments. This will help businesses make data-driven decisions and improve customer satisfaction.\n",
    "\n",
    "### Business Overview\n",
    "Sentiment analysis is vital across industries like retail, hospitality, and finance. It helps monitor brand reputation, identify customer pain points, and tailor marketing strategies. For example, analyzing product reviews or social media feedback enables companies to enhance customer experiences and address issues promptly, driving growth and improving brand loyalty.\n",
    "\n",
    "### Objective of the Project\n",
    "The project aims to build a sentiment analysis model to classify text into positive, negative, or neutral sentiments. It involves preprocessing text data, extracting features, training machine learning or deep learning models, and evaluating performance. The final goal is to create a tool that automates sentiment analysis, helping businesses analyze text data efficiently and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "### Data repository\n",
    "The dataset, known as \"Tweet Sentiment Analysis\", was downloaded from Kaggle . It contains text data from tweets, where each tweet is labeled with a sentiment: positive, negative, or neutral. The dataset can be [Download Here](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset)\n",
    "\n",
    "### Data overview\n",
    "\n",
    "The dataset provided contains text samples with four columns: textID, text, selected_text, and sentiment. Each row represents a unique text entry, where:\n",
    "\n",
    "1. textID is a unique identifier for each text.\n",
    "2. text contains the full sentence or phrase.\n",
    "3. selected_text highlights the specific part of the text that reflects the sentiment.\n",
    "4. sentiment labels the text as positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7  50e14c0bb8                                         Soooo high   \n",
       "8  e050245fbd                                        Both of you   \n",
       "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "\n",
       "                                       selected_text sentiment  \n",
       "0                I`d have responded, if I were going   neutral  \n",
       "1                                           Sooo SAD  negative  \n",
       "2                                        bullying me  negative  \n",
       "3                                     leave me alone  negative  \n",
       "4                                      Sons of ****,  negative  \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral  \n",
       "6                                                fun  positive  \n",
       "7                                         Soooo high   neutral  \n",
       "8                                        Both of you   neutral  \n",
       "9                       Wow... u just became cooler.  positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27471</th>\n",
       "      <td>15bb120f57</td>\n",
       "      <td>i`m defying gravity. and nobody in alll of oz,...</td>\n",
       "      <td>i`m defying gravity. and nobody in alll of oz,...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27472</th>\n",
       "      <td>8f5adc47ec</td>\n",
       "      <td>http://twitpic.com/663vr - Wanted to visit the...</td>\n",
       "      <td>were too late</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27473</th>\n",
       "      <td>a208770a32</td>\n",
       "      <td>in spoke to you yesterday and u didnt respond...</td>\n",
       "      <td>in spoke to you yesterday and u didnt respond ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27474</th>\n",
       "      <td>8f14bb2715</td>\n",
       "      <td>So I get up early and I feel good about the da...</td>\n",
       "      <td>I feel good ab</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>b78ec00df5</td>\n",
       "      <td>enjoy ur night</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "27471  15bb120f57  i`m defying gravity. and nobody in alll of oz,...   \n",
       "27472  8f5adc47ec  http://twitpic.com/663vr - Wanted to visit the...   \n",
       "27473  a208770a32   in spoke to you yesterday and u didnt respond...   \n",
       "27474  8f14bb2715  So I get up early and I feel good about the da...   \n",
       "27475  b78ec00df5                                     enjoy ur night   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "27471  i`m defying gravity. and nobody in alll of oz,...   neutral  \n",
       "27472                                      were too late  negative  \n",
       "27473  in spoke to you yesterday and u didnt respond ...   neutral  \n",
       "27474                                     I feel good ab  positive  \n",
       "27475                                              enjoy  positive  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preview the dataset\n",
    "display(df.head(10))\n",
    "display(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape indicates that the dataset has 27481 rows and 4 Columns\n"
     ]
    }
   ],
   "source": [
    "# check info of the data\n",
    "print(f\"The shape indicates that the dataset has {df.shape[0]} rows and {df.shape[1]} Columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check more info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             1\n",
       "selected_text    1\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the dataset has 0 missing texts or values\n"
     ]
    }
   ],
   "source": [
    "# droping the missing values\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Now the dataset has {df.isnull().sum().sum()} missing texts or values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains 0 duplicated rows\n"
     ]
    }
   ],
   "source": [
    "# Checkinf for duplicated texts\n",
    "print(f\"This dataset contains {df.duplicated().sum()} duplicated rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['textID', 'text', 'selected_text', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 4 columns, lets review the importance of each column as illustrated in the table below\n",
    "\n",
    "|Column name| Description | Status |\n",
    "|--------------------|-------------------------------------------|--------|\n",
    "|**textID**          | A unique identifier for each tweet.       | Drop   |\n",
    "|**text**            | The full original text of the tweet.      | Keep   |\n",
    "|**selected_text**   | Text extract that shows the sentiment.    | Drop   |\n",
    "|**sentiment**       | The sentiment label                       | Keep   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns\n",
    "df.drop(columns=['textID', 'selected_text'], inplace=True)\n",
    "#print columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing \n",
    "This process involves standardizing text data that is by: \n",
    "1. Converting to lowercase\n",
    "2. Removing special characters, numbers, and punctuation\n",
    "3. Removing stopwords\n",
    "4. Lemmatization that is reducing words to their root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Since stopword removal can eliminate important words like \"not,\" sentiment can be misinterpreted. \n",
    "To counter this, we define a set of common negation words to preserve and detect sentiment reversals. \n",
    "This includes standard negations and contractions like \"not,\" \"no,\" \"never,\" \"n't,\" \"can't,\" etc.\n",
    "\"\"\"\n",
    "negation_words = {\"not\", \"no\", \"never\", \"n't\", \"can't\", \"won't\", \"shouldn't\", \"isn't\", \"wasn't\", \"couldn't\"}\n",
    "# define a function\n",
    "def preprocess_text(text):\n",
    "    # standardize text to lowercased\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text) \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) \n",
    "    \n",
    "    words = text.split()\n",
    "    \n",
    "    # Negation handling\n",
    "    processed_words = []\n",
    "    negate = False\n",
    "    \n",
    "    for word in words:\n",
    "        if word in negation_words:\n",
    "            negate = True\n",
    "            processed_words.append(word)\n",
    "        elif negate:\n",
    "            processed_words.append(f\"not_{word}\")\n",
    "            negate = False\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    \n",
    "    # Remove stopwords but keep negation words\n",
    "    processed_words = [word for word in processed_words if word not in stop_words or word in negation_words]\n",
    "    # Lemmatization\n",
    "    processed_words = [lemmatizer.lemmatize(word) for word in processed_words]\n",
    "    return \" \".join(processed_words)\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the orginal text before text processing:                                                 text\n",
      "0                I`d have responded, if I were going\n",
      "1      Sooo SAD I will miss you here in San Diego!!!\n",
      "2                          my boss is bullying me...\n",
      "3                     what interview! leave me alone\n",
      "4   Sons of ****, why couldn`t they put them on t...\n",
      "____________________________________________________________________________________________________\n",
      "This is the new text after text processing:                              cleaned_text\n",
      "0                      id responded going\n",
      "1                 sooo sad miss san diego\n",
      "2                            bos bullying\n",
      "3                   interview leave alone\n",
      "4  son couldnt put release already bought\n"
     ]
    }
   ],
   "source": [
    "# preview the text processed data\n",
    "print(f\"This is the orginal text before text processing: {df[['text']].head()}\")\n",
    "print(\"_\"*100)\n",
    "# After text processing\n",
    "print(f\"This is the new text after text processing: {df[['cleaned_text']].head()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "### Tokenization and padding\n",
    "\n",
    "The process of tokenization and padding involves converting text into numerical format for machine learning models. Tokenization breaks text into words or subwords and maps them to unique numerical indices. Padding ensures that all sequences have the same length by adding zeros or placeholders to shorter sequences. This standardization allows models to process text efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])\n",
    "X = tokenizer.texts_to_sequences(df['cleaned_text'])\n",
    "# Pad sequences to a fixed length\n",
    "# a twitter comment usully is of about a mean of 25 words\n",
    "# doubled it\n",
    "max_len = 50\n",
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiment labels to numerical values\n",
    "y = df['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intiate the sequential model\n",
    "model = Sequential()\n",
    "# Embedding layer to remove input_length\n",
    "model.add(Embedding(input_dim=5001, output_dim=128))  \n",
    "# 1D Convolutional layer\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "# Global Max Pooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# Fully connected layers\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: negative, neutral, positive\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      " sentiment\n",
      "1    11117\n",
      "2     8582\n",
      "0     7781\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking the class distribution before splittng the data\n",
    "print(\"Original class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data\n",
    "# using test size of 20% and random state of 42 and parameter strarify= y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " sentiment\n",
      "1    8894\n",
      "2    6865\n",
      "0    6225\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution:\n",
      " sentiment\n",
      "1    2223\n",
      "2    1717\n",
      "0    1556\n",
      "Name: count, dtype: int64\n",
      "The dataset contains class imbalances, but the diffrence between them is not huge, hence no need of balancing them using SMOTE\n"
     ]
    }
   ],
   "source": [
    "#checking the class distribution after spliting the data\n",
    "print(\"Training set class distribution:\\n\", y_train.value_counts())\n",
    "print(\"Test set class distribution:\\n\", y_test.value_counts())\n",
    "print(\"The dataset contains class imbalances, but the diffrence between them is not huge, hence no need of balancing them using SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.5502 - loss: 0.9184 - val_accuracy: 0.7080 - val_loss: 0.6868\n",
      "Epoch 2/5\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.7610 - loss: 0.5865 - val_accuracy: 0.7069 - val_loss: 0.6985\n",
      "Epoch 3/5\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.8373 - loss: 0.4413 - val_accuracy: 0.6936 - val_loss: 0.7486\n",
      "Epoch 4/5\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.8957 - loss: 0.3088 - val_accuracy: 0.6843 - val_loss: 0.8677\n",
      "Epoch 5/5\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.9346 - loss: 0.2042 - val_accuracy: 0.6696 - val_loss: 1.0383\n"
     ]
    }
   ],
   "source": [
    "# Train the sentiment analysis model for 5 epochs with a batch size of 64, using training data.\n",
    "# Validate performance on the test set after each epoch.\n",
    "sent_model = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.639692485332489,\n",
       "  0.7633733749389648,\n",
       "  0.8296488523483276,\n",
       "  0.8887372612953186,\n",
       "  0.928993821144104],\n",
       " 'loss': [0.8004828095436096,\n",
       "  0.5861129760742188,\n",
       "  0.44870051741600037,\n",
       "  0.3200085759162903,\n",
       "  0.21639761328697205],\n",
       " 'val_accuracy': [0.7079694271087646,\n",
       "  0.7068777084350586,\n",
       "  0.6935953497886658,\n",
       "  0.6843158602714539,\n",
       "  0.6695778965950012],\n",
       " 'val_loss': [0.6867584586143494,\n",
       "  0.6985465884208679,\n",
       "  0.7485771775245667,\n",
       "  0.8676957488059998,\n",
       "  1.038257360458374]}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the training history, including accuracy and loss for both training and validation sets.\n",
    "sent_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6593 - loss: 1.0567\n",
      "Test Accuracy: 0.6696\n",
      "Test Loss: 1.0383\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model \n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# measure its performance.\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to predict sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping labels\n",
    "sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "#define a function\n",
    "def predict_sentiment():\n",
    "    user_text = input(\"Enter a tweet: \")\n",
    "    # Preprocess the input text\n",
    "    processed_text = preprocess_text(user_text)\n",
    "    # Tokenize and pad the sequence\n",
    "    sequence = tokenizer.texts_to_sequences([processed_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_class = prediction.argmax(axis=1)[0]  # Get class with highest probability\n",
    "    \n",
    "    print(f\"\\nTweet: {user_text}\")\n",
    "    print(f\"Predicted Sentiment: {sentiment_labels[predicted_class]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples of predicted sentiments\n",
    "This is how it works the user inputs a tweep comment and the system predicts if it is postive, neutral or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      "Tweet: William will not win the election in 2027, mark this tweet, will be open to debate on 2027\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      "Tweet: I really hate you, i dont want to see you again\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "Tweet: congratulations team, we won, i knew this team was strong\n",
      "Predicted Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      "Tweet: I really loved the way we spent time together, it was nice\n",
      "Predicted Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\n",
      "Tweet: allow me not to comment on this issue\n",
      "Predicted Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      "Tweet: I'm not sure if i will make it to come \n",
      "Predicted Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
